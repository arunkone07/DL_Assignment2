{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8008008,"sourceType":"datasetVersion","datasetId":4716602}],"dockerImageVersionId":30674,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-03T12:27:22.272220Z","iopub.execute_input":"2024-04-03T12:27:22.272481Z","iopub.status.idle":"2024-04-03T12:27:29.823142Z","shell.execute_reply.started":"2024-04-03T12:27:22.272457Z","shell.execute_reply":"2024-04-03T12:27:29.822370Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"print(torch.cuda.is_available())","metadata":{"execution":{"iopub.status.busy":"2024-04-03T12:27:31.255018Z","iopub.execute_input":"2024-04-03T12:27:31.255510Z","iopub.status.idle":"2024-04-03T12:27:31.291916Z","shell.execute_reply.started":"2024-04-03T12:27:31.255481Z","shell.execute_reply":"2024-04-03T12:27:31.290870Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the CNN architecture\nclass CNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1) #256, 128, 64, 32, 16\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)                               #16x16x32\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)#16x16x64\n#         self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)                            #8x8x64\n        self.fc1 = nn.Linear(32*8*8, 128)\n        self.fc2 = nn.Linear(128, num_classes)\n        self.activation = nn.GELU()\n\n    def forward(self, x):\n        x = self.activation(self.conv1(x)) #256x256\n        x = self.pool(x)                   #128x128\n        x = self.activation(self.conv2(x)) \n        x = self.pool(x)                   #64x64\n        x = self.activation(self.conv2(x))\n        x = self.pool(x)                   #32x32\n        x = self.activation(self.conv2(x))\n        x = self.pool(x)                   #16x16\n        x = self.activation(self.conv2(x))\n        x = self.pool(x)                   #8x8\n        x = x.view(-1, 8*8*32)\n        x = self.activation(self.fc1(x))\n        x = self.fc2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-03T12:27:33.914255Z","iopub.execute_input":"2024-04-03T12:27:33.914611Z","iopub.status.idle":"2024-04-03T12:27:33.924611Z","shell.execute_reply.started":"2024-04-03T12:27:33.914581Z","shell.execute_reply":"2024-04-03T12:27:33.923613Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nnum_classes = 10\nlearning_rate = 0.003\nbatch_size = 100\nnum_epochs = 10\n\n# Load and transform the data\ntransform = transforms.Compose([\n    transforms.Resize((256,256)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n\n\ntrain_dataset = torchvision.datasets.ImageFolder(root='/kaggle/input/inaturalist/inaturalist_12K/train', transform=transform)\n\ntrain_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [8000, 1999])\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True)\n\ntest_dataset = torchvision.datasets.ImageFolder(root='/kaggle/input/inaturalist/inaturalist_12K/val', transform=transform)\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T12:27:36.266613Z","iopub.execute_input":"2024-04-03T12:27:36.267512Z","iopub.status.idle":"2024-04-03T12:27:46.886402Z","shell.execute_reply.started":"2024-04-03T12:27:36.267476Z","shell.execute_reply":"2024-04-03T12:27:46.885423Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Initialize the CNN\nmodel = CNN(num_classes)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\ndef accuracy(self, loader):\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in loader:\n            images, labels = data[0].to(device), data[1].to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = correct / total\n    print('Accuracy: ', accuracy)\n        \n# Training loop\ntotal_step = len(train_loader)\nfor epoch in range(num_epochs):\n    total_loss = 0\n    for i, (images, labels) in enumerate(train_loader):\n        images, labels = images.to(device), labels.to(device)\n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        \n        if (i+1)%10 == 0:\n            print('Epoch [{}/{}], Step [{}/{}], Avg Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, total_loss/(i+1)))\n\n    accuracy(val_loader)\n    print(\"\\n\")\n    \naccuracy(test_loader)\n# Optionally, save the trained model\ntorch.save(model.state_dict(), 'cnn_model.ckpt')","metadata":{"execution":{"iopub.status.busy":"2024-04-03T12:27:50.009141Z","iopub.execute_input":"2024-04-03T12:27:50.009513Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch [1/10], Step [10/80], Avg Loss: 2.3244\n","output_type":"stream"}]}]}