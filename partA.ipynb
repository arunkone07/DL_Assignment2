{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8008008,"sourceType":"datasetVersion","datasetId":4716602}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport wandb\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-08T11:11:25.341973Z","iopub.execute_input":"2024-04-08T11:11:25.342624Z","iopub.status.idle":"2024-04-08T11:11:33.541181Z","shell.execute_reply.started":"2024-04-08T11:11:25.342596Z","shell.execute_reply":"2024-04-08T11:11:33.540389Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"wandb.login()\n# 3dc8367198d0460ba99efb94e713de7e299e685d","metadata":{"execution":{"iopub.status.busy":"2024-04-08T11:11:33.542863Z","iopub.execute_input":"2024-04-08T11:11:33.543283Z","iopub.status.idle":"2024-04-08T11:11:38.419603Z","shell.execute_reply.started":"2024-04-08T11:11:33.543256Z","shell.execute_reply":"2024-04-08T11:11:38.418715Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-08T11:11:38.420664Z","iopub.execute_input":"2024-04-08T11:11:38.421144Z","iopub.status.idle":"2024-04-08T11:11:38.477496Z","shell.execute_reply.started":"2024-04-08T11:11:38.421114Z","shell.execute_reply":"2024-04-08T11:11:38.476504Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes', \n    'metric': {\n      'name': 'val_accuracy',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n        'kernel_size':{\n            'values': [[3,3,3,3,3], [3,5,5,7,7], [7,7,5,5,3]]\n        },\n        'dropout': {\n            'values': [0, 0.2, 0.4]\n        },\n        'lr': {\n            'values': [0.0003, 0.001, 0.003]\n        },\n        'activation': {\n            'values': ['relu', 'gelu', 'silu', 'mish']\n        },\n        'optimizer': {\n            'values': ['adam', 'nadam']\n        },\n        'batch_norm':{\n            'values': ['true','false']\n        },\n        'filt_org':{\n            'values': ['equal', 'double', 'half']\n        },\n        'num_filters': {\n            'values': [32,64,128]\n        },\n        'data_aug': {\n            'values': ['true','false']\n        },\n        'batch_size': {\n            'values': [32, 64, 128]\n        },\n        'num_dense':{\n            'values': [64, 128, 256]\n        }\n    }\n}\n\noptimizers = {\n    'adam': optim.Adam,\n    'nadam': optim.NAdam\n}\n\n\nsweep_id = wandb.sweep(sweep=sweep_config, project='Assignment2')","metadata":{"execution":{"iopub.status.busy":"2024-04-08T11:11:38.479677Z","iopub.execute_input":"2024-04-08T11:11:38.480373Z","iopub.status.idle":"2024-04-08T11:11:39.438910Z","shell.execute_reply.started":"2024-04-08T11:11:38.480344Z","shell.execute_reply":"2024-04-08T11:11:39.438049Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Create sweep with ID: cli0ri7q\nSweep URL: https://wandb.ai/arun_cs23m017/Assignment2/sweeps/cli0ri7q\n","output_type":"stream"}]},{"cell_type":"code","source":"# Hyperparameters\nnum_classes = 10\nnum_epochs = 10\nimg_size = 256\n\n# Load and transform the data\ntransform = transforms.Compose([\n    transforms.Resize((256,256)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ntransform_aug = transforms.Compose([\n    transforms.Resize((256,256)),\n    transforms.RandomRotation(degrees=30),\n    transforms.RandomVerticalFlip(),\n    transforms.ColorJitter(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n\ndef accuracy(model, criterion, loader):\n    correct = 0\n    total = 0\n    loss = 0\n    with torch.no_grad():\n        for data in loader:\n            images, labels = data[0].to(device), data[1].to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            loss += criterion(outputs, labels).item() * labels.size(0)\n    accuracy = correct / total\n    loss /= total\n    return accuracy, loss","metadata":{"execution":{"iopub.status.busy":"2024-04-08T11:11:39.439957Z","iopub.execute_input":"2024-04-08T11:11:39.440256Z","iopub.status.idle":"2024-04-08T11:11:39.450270Z","shell.execute_reply.started":"2024-04-08T11:11:39.440232Z","shell.execute_reply":"2024-04-08T11:11:39.449408Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Define the CNN architecture\nclass CNN(nn.Module):\n    def __init__(self, config, num_classes=10):\n        super(CNN, self).__init__()\n        self.config = config\n        \n        if config.filt_org == 'double':\n            self.filt_factor = 2\n        elif config.filt_org == 'half':\n            self.filt_factor = 0.5\n        else:\n            self.filt_factor = 1\n            \n        if(self.config.data_aug == 'true'):\n            self.train_dataset = torchvision.datasets.ImageFolder(root='/kaggle/input/inaturalist/inaturalist_12K/train', transform=transform_aug)\n        else:\n            self.train_dataset = torchvision.datasets.ImageFolder(root='/kaggle/input/inaturalist/inaturalist_12K/train', transform=transform)\n\n        self.train_dataset, self.val_dataset = torch.utils.data.random_split(self.train_dataset, [8000, 1999])\n\n        self.train_loader = torch.utils.data.DataLoader(dataset=self.train_dataset, batch_size=self.config.batch_size, shuffle=True)\n        self.val_loader = torch.utils.data.DataLoader(dataset=self.val_dataset, batch_size=self.config.batch_size, shuffle=True)\n\n        self.test_dataset = torchvision.datasets.ImageFolder(root='/kaggle/input/inaturalist/inaturalist_12K/val', transform=transform)\n        self.test_loader = torch.utils.data.DataLoader(dataset=self.test_dataset, batch_size=self.config.batch_size, shuffle=True)\n        \n        img_size = 256\n        \n        in_ch = 3\n        out_ch = config.num_filters\n        self.conv1 = nn.Conv2d(in_ch, out_ch, config.kernel_size[0], stride=1, padding=1) \n        self.bn1 = nn.BatchNorm2d(out_ch)\n        \n        img_size = (img_size - config.kernel_size[0] + 3) // 2\n        in_ch = out_ch\n        out_ch = int(config.num_filters * self.filt_factor)\n        self.conv2 = nn.Conv2d(in_ch, out_ch, config.kernel_size[1], stride=1, padding=1)  \n        self.bn2 = nn.BatchNorm2d(out_ch)\n        \n        img_size = (img_size - config.kernel_size[1] + 3) // 2\n        in_ch = out_ch\n        out_ch = int(config.num_filters * self.filt_factor**2)\n        self.conv3 = nn.Conv2d(in_ch, out_ch, config.kernel_size[2], stride=1, padding=1)  \n        self.bn3 = nn.BatchNorm2d(out_ch)\n        \n        img_size = (img_size - config.kernel_size[2] + 3) // 2\n        in_ch = out_ch\n        out_ch = int(config.num_filters * self.filt_factor**3)\n        self.conv4 = nn.Conv2d(in_ch, out_ch, config.kernel_size[3], stride=1, padding=1)  \n        self.bn4 = nn.BatchNorm2d(out_ch)\n        \n        img_size = (img_size - config.kernel_size[3] + 3) // 2\n        in_ch = out_ch\n        out_ch = int(config.num_filters * self.filt_factor**4)\n        self.conv5 = nn.Conv2d(in_ch, out_ch, config.kernel_size[4], stride=1, padding=1)   \n        self.bn5 = nn.BatchNorm2d(out_ch)\n        \n        img_size = (img_size - config.kernel_size[4] + 3) // 2\n        self.x_shape = out_ch * img_size * img_size\n        \n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)      \n        \n        self.fc1 = nn.Linear(self.x_shape, config.num_dense)\n        self.bn1d = nn.BatchNorm1d(config.num_dense)\n        self.dropout = nn.Dropout(p=config.dropout)\n        self.fc2 = nn.Linear(config.num_dense, num_classes)\n        \n        if config.activation == 'relu':\n            self.activation = F.relu\n        elif config.activation == 'gelu':\n            self.activation = F.gelu\n        elif config.activation == 'silu':\n            self.activation = F.silu\n        else:\n            self.activation = F.mish\n        \n    def forward(self, x):\n        \n        x = self.activation(self.conv1(x)) \n        if(self.config.batch_norm == 'true'):\n            x = self.bn1(x)\n        x = self.pool(x)  \n        \n        x = self.activation(self.conv2(x)) \n        if(self.config.batch_norm == 'true'):\n            x = self.bn2(x)\n        x = self.pool(x)   \n        \n        x = self.activation(self.conv3(x))\n        if(self.config.batch_norm == 'true'):\n            x = self.bn3(x)\n        x = self.pool(x)   \n        \n        x = self.activation(self.conv4(x))\n        if(self.config.batch_norm == 'true'):\n            x = self.bn4(x)\n        x = self.pool(x)   \n        \n        x = self.activation(self.conv5(x))\n        if(self.config.batch_norm == 'true'):\n            x = self.bn5(x)\n        x = self.pool(x)   \n        \n        x = x.view(-1, self.x_shape)\n        \n        x = self.activation(self.fc1(x))\n        if(self.config.batch_norm == 'true'):\n            x = self.bn1d(x)\n            \n        x = self.dropout(x)\n        \n        x = self.fc2(x)\n        return x\n    \n    def train(self, model, criterion, optimizer):\n        total_step = len(self.train_loader)\n        for epoch in range(num_epochs):\n            train_loss = 0\n            correct = 0\n            for i, (images, labels) in enumerate(self.train_loader):\n                # Forward pass\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n\n                _, predicted = torch.max(outputs.data, 1)\n                correct += (predicted == labels).sum().item()\n                # Backward and optimize\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                train_loss += loss.item()\n                if (i+1)%10 == 0:\n                    print('Epoch [{}/{}], Step [{}/{}], Avg Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, train_loss/(i+1)))\n\n            train_loss /= total_step\n            train_acc = correct / (total_step * self.config.batch_size)\n\n            val_acc, val_loss = accuracy(model, criterion, self.val_loader)\n\n            print(\"Train\\n:Accuracy:\", train_acc, \"Loss:\", train_loss)\n            print(\"Validation\\n:Accuracy:\", val_acc, \"Loss:\", val_loss, \"\\n\")\n            wandb.log({'train_accuracy': train_acc})\n            wandb.log({'train_loss': train_loss})\n            wandb.log({'val_accuracy': val_acc})\n            wandb.log({'val_loss': val_loss})\n","metadata":{"execution":{"iopub.status.busy":"2024-04-08T11:11:39.451626Z","iopub.execute_input":"2024-04-08T11:11:39.451880Z","iopub.status.idle":"2024-04-08T11:11:39.484556Z","shell.execute_reply.started":"2024-04-08T11:11:39.451859Z","shell.execute_reply":"2024-04-08T11:11:39.483574Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def main():\n    with wandb.init() as run:\n        bn = 0\n        aug = 0\n        org = 1\n        ks = \"\"\n        \n        if(wandb.config.batch_norm == 'true'):\n            bn = 1\n            \n        if(wandb.config.data_aug == 'true'):\n            aug = 1\n            \n        if(wandb.config.filt_org == 'double'):\n            org = 2\n        elif(wandb.config.filt_org == 'half'):\n            org = 0.5\n            \n        for i in range(0,5,2):\n            ks += str(wandb.config.kernel_size[i])\n            \n        wandb.run.name =  (wandb.config.activation + \"-bn_\"+str(bn) + \"-aug_\"+str(aug) + \"-drop_\"+str(wandb.config.dropout) + \n                           \"-bs_\"+str(wandb.config.batch_size) +\"-lr_\"+str(wandb.config.lr) + \"-filt_\"+str(wandb.config.num_filters) +\n                           \"-org_\"+str(org) + \"-ks_\"+ks + \"-fc_\"+str(wandb.config.num_dense) + \"-\"+wandb.config.optimizer)\n        model = CNN(wandb.config, num_classes).to(device)\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optimizers[wandb.config.optimizer](model.parameters(), lr=wandb.config.lr)\n        model.train(model, criterion, optimizer)\n\nwandb.agent('air75u6r', function=main, count=10) # calls main function for count number of times.\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-04-08T11:11:39.485707Z","iopub.execute_input":"2024-04-08T11:11:39.486014Z","iopub.status.idle":"2024-04-08T11:13:27.502757Z","shell.execute_reply.started":"2024-04-08T11:11:39.485990Z","shell.execute_reply":"2024-04-08T11:13:27.501759Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vdkytdsv with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: mish\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: true\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_aug: true\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilt_org: half\n\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: [3, 5, 5, 7, 7]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.003\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dense: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m017\u001b[0m (\u001b[33marun_cs23m017\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240408_111151-vdkytdsv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/arun_cs23m017/Assignment2/runs/vdkytdsv' target=\"_blank\">upbeat-sweep-11</a></strong> to <a href='https://wandb.ai/arun_cs23m017/Assignment2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/arun_cs23m017/Assignment2/sweeps/air75u6r' target=\"_blank\">https://wandb.ai/arun_cs23m017/Assignment2/sweeps/air75u6r</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/arun_cs23m017/Assignment2' target=\"_blank\">https://wandb.ai/arun_cs23m017/Assignment2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/arun_cs23m017/Assignment2/sweeps/air75u6r' target=\"_blank\">https://wandb.ai/arun_cs23m017/Assignment2/sweeps/air75u6r</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/arun_cs23m017/Assignment2/runs/vdkytdsv' target=\"_blank\">https://wandb.ai/arun_cs23m017/Assignment2/runs/vdkytdsv</a>"},"metadata":{}},{"name":"stdout","text":"Epoch [1/10], Step [10/125], Avg Loss: 2.3410\nEpoch [1/10], Step [20/125], Avg Loss: 2.2988\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">upbeat-sweep-11</strong> at: <a href='https://wandb.ai/arun_cs23m017/Assignment2/runs/vdkytdsv' target=\"_blank\">https://wandb.ai/arun_cs23m017/Assignment2/runs/vdkytdsv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240408_111151-vdkytdsv/logs</code>"},"metadata":{}}]}]}
